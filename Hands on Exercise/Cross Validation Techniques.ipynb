{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ceedc3be",
   "metadata": {},
   "source": [
    "# <center>Cross Validation Techniques</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bea33ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold, StratifiedKFold, LeavePOut, LeaveOneOut, ShuffleSplit, TimeSeriesSplit\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2295a41a",
   "metadata": {},
   "source": [
    "### `Hold Out Cross Validation`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3141a1be",
   "metadata": {},
   "source": [
    "In this technique, we consider the entire dataset. The dataset is split into two parts -   \n",
    "Normally the thumb-rule is 70-30, where, 70% of the entire data is considered as training data.   \n",
    "And the remaining 30% is considered as test/validation data.  \n",
    "Alternative rule is 80-20.\n",
    "\n",
    "<b>Advantages:</b>\n",
    "- Quick to execute.\n",
    "\n",
    "<b>Disadvantage:</b>\n",
    "- Not suitable for an imbalance dataset.\n",
    "- Not suitable for very small dataset. Large chunk of data gets deprived of training of model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a0b578c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data is 0.9619047619047619\n",
      "Accuracy on testing data is 1.0\n"
     ]
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "X= iris.data\n",
    "y = iris.target\n",
    "\n",
    "log = LogisticRegression()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "log.fit(X_train, y_train)\n",
    "\n",
    "print(\"Accuracy on training data is\", accuracy_score(y_train, log.predict(X_train)))\n",
    "print(\"Accuracy on testing data is\", accuracy_score(y_test, log.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c4250b",
   "metadata": {},
   "source": [
    "### `K-Fold Cross Validation`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92632580",
   "metadata": {},
   "source": [
    "In this technique, the entire dataset is partitioned into k parts.  \n",
    "Each partition is called a fold.  \n",
    "We use 1 fold for validation/test.  \n",
    "We use K - 1 fold for training.  \n",
    "\n",
    "This technique is repeated K times until each fold is used as a validation data.  \n",
    "And remaining folds are used as testing data.  \n",
    "The final accuracy of the model is computed by taking the mean accuracy K-model's validation data.\n",
    "\n",
    "<b>Advantages:</b>\n",
    "- The entire dataset is used as training set and validation set.  \n",
    "\n",
    "<b>Disadvantages:</b>\n",
    "- This technique should not be used for imbalanced datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0eca8087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Scores are: [1.         1.         0.86666667 0.93333333 0.83333333]\n",
      "Average Cross Validation Score is: 0.9266666666666665\n"
     ]
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "X= iris.data\n",
    "y = iris.target\n",
    "\n",
    "log = LogisticRegression()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "log.fit(X_train, y_train)\n",
    "\n",
    "kf = KFold(n_splits=5)\n",
    "\n",
    "score = cross_val_score(log, X, y, cv=kf)\n",
    "\n",
    "print(\"Cross Validation Scores are:\", score)\n",
    "print(\"Average Cross Validation Score is:\", score.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1ee154",
   "metadata": {},
   "source": [
    "### `Stratified K-Fold Cross Validation`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59278df6",
   "metadata": {},
   "source": [
    "This is an enhanced version of K-Fold cross validation technique.  \n",
    "Generally used with imbalanced datasets.  \n",
    "In this technique, the entire dataset is partitioned into k parts of equal sizes.  \n",
    "The training instance ration will be same as the original dataset ratio.   \n",
    "\n",
    "<b>Disadvantages:</b>\n",
    "- Not suitable for time series data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2dd02f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StratifiedKFold(n_splits=2, random_state=None, shuffle=False)\n",
      "Train: [1 3] Test: [0 2]\n",
      "Train: [0 2] Test: [1 3]\n"
     ]
    }
   ],
   "source": [
    "X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])\n",
    "y = np.array([0, 0, 1, 1])\n",
    "\n",
    "skf = StratifiedKFold(n_splits=2)\n",
    "skf.get_n_splits(X, y)\n",
    "\n",
    "print(skf)\n",
    "\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    print(\"Train:\", train_index, \"Test:\", test_index)\n",
    "    \n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87c2798",
   "metadata": {},
   "source": [
    "## `Leave P Out Cross Validation`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affcd00d",
   "metadata": {},
   "source": [
    "This technique is an exhaustive cross validation technique in which we consider P-samples used as validation set (test)  \n",
    "And the remaining (n-P) samples are used as training set.  \n",
    "For example, in a dataset with n=100 data, if we use P=10, then in each iteration, 10 values will be used as validation dataset and the remaining 90 dataset are used as test dataset.  \n",
    "This process is repeated until the whole dataset gets divided into validation sets of P-samples and (n-P) training samples.  \n",
    "\n",
    "<b>Advantages:</b>\n",
    "- All the data samples get selected as both training and validation samples.\n",
    "\n",
    "<b>Disadvantages:</b>\n",
    "- High computation time.\n",
    "- Not suitable for imbalanced datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d6c2d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeavePOut(p=2)\n",
      "Train: [2 3] Test: [0 1]\n",
      "Train: [1 3] Test: [0 2]\n",
      "Train: [1 2] Test: [0 3]\n",
      "Train: [0 3] Test: [1 2]\n",
      "Train: [0 2] Test: [1 3]\n",
      "Train: [0 1] Test: [2 3]\n"
     ]
    }
   ],
   "source": [
    "X = np.array([[1, 2], [3, 4], [5, 6], [7, 8]])\n",
    "y = np.array([1, 2, 3, 4])\n",
    "\n",
    "lpo = LeavePOut(2)\n",
    "lpo.get_n_splits(X)\n",
    "\n",
    "print(lpo)\n",
    "\n",
    "for train_index, test_index in lpo.split(X, y):\n",
    "    print(\"Train:\", train_index, \"Test:\", test_index)\n",
    "    \n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087ad6cd",
   "metadata": {},
   "source": [
    "## `Leave One Out Cross Validation` "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b73d40",
   "metadata": {},
   "source": [
    "This technique is very similar to the Leave P Out Technique, except P is always 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a09188e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeavePOut(p=2)\n",
      "Train: [2 3] Test: [0 1]\n",
      "Train: [1 3] Test: [0 2]\n",
      "Train: [1 2] Test: [0 3]\n",
      "Train: [0 3] Test: [1 2]\n",
      "Train: [0 2] Test: [1 3]\n",
      "Train: [0 1] Test: [2 3]\n"
     ]
    }
   ],
   "source": [
    "X = np.array([[1, 2], [3, 4], [5, 6], [7, 8]])\n",
    "y = np.array([1, 2, 3, 4])\n",
    "\n",
    "loo = LeavePOut(2)\n",
    "loo.get_n_splits(X)\n",
    "\n",
    "print(loo)\n",
    "\n",
    "for train_index, test_index in loo.split(X, y):\n",
    "    print(\"Train:\", train_index, \"Test:\", test_index)\n",
    "    \n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95ae027",
   "metadata": {},
   "source": [
    "## `Monte-Carlo : Shuffle Split Cross Validation`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6c9ff4",
   "metadata": {},
   "source": [
    "In this technique, the dataset gets randomly partitioned into training set and the validation set.  \n",
    "Here, we decide the percentage of the dataset we want to use as the training set and the percentage that we want to use as the validation set.  \n",
    "If the added percentage of the training and testing sets is not equal to 100%, the remaining data is not used in either training or testing dataset.  \n",
    "\n",
    "For example,  \n",
    "Lets say we have 100 samples, and 60% of samples are to be used as training set and if we mention 20% of dataset to be used as testing set, the remaining 20% data will not be used.\n",
    "\n",
    "<b>Advantages:</b>\n",
    "- We are free to set the size of training and testing sets.\n",
    "- We can also choose the number of repetition.\n",
    "- It is not dependent on number of folds.\n",
    "\n",
    "<b>Disadvantages:</b>\n",
    "- Few samples may not be selected for either training or testing set.\n",
    "- Not suitable for imbalanced data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cab144a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ShuffleSplit(n_splits=5, random_state=0, test_size=0.25, train_size=None)\n",
      "TRAIN: [1 3 0 4] TEST: [5 2]\n",
      "TRAIN: [4 0 2 5] TEST: [1 3]\n",
      "TRAIN: [1 2 4 0] TEST: [3 5]\n",
      "TRAIN: [3 4 1 0] TEST: [5 2]\n",
      "TRAIN: [3 5 1 0] TEST: [2 4]\n",
      "\n",
      "\n",
      "\n",
      "TRAIN: [1 3 0] TEST: [5 2]\n",
      "TRAIN: [4 0 2] TEST: [1 3]\n",
      "TRAIN: [1 2 4] TEST: [3 5]\n",
      "TRAIN: [3 4 1] TEST: [5 2]\n",
      "TRAIN: [3 5 1] TEST: [2 4]\n"
     ]
    }
   ],
   "source": [
    "X = np.array([[1, 2], [3, 4], [5, 6], [7, 8], [3, 4], [5, 6]])\n",
    "y = np.array([1, 2, 1, 2, 1, 2])\n",
    "\n",
    "rs = ShuffleSplit(n_splits=5, test_size=0.25, random_state=0)\n",
    "rs.get_n_splits(X)\n",
    "\n",
    "print(rs)\n",
    "\n",
    "for train_index, test_index in rs.split(X):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    \n",
    "print(\"\\n\\n\")\n",
    "\n",
    "rs = ShuffleSplit(n_splits=5, train_size=0.5, test_size=0.25, random_state=0)\n",
    "\n",
    "for train_index, test_index in rs.split(X):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54400aa6",
   "metadata": {},
   "source": [
    "## `Time Series Cross Validation`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54edea6a",
   "metadata": {},
   "source": [
    "This technique is all about performing cross validation on the time series data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "90449827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None)\n",
      "TRAIN: [0] TEST: [1]\n",
      "TRAIN: [0 1] TEST: [2]\n",
      "TRAIN: [0 1 2] TEST: [3]\n",
      "TRAIN: [0 1 2 3] TEST: [4]\n",
      "TRAIN: [0 1 2 3 4] TEST: [5]\n",
      "TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None)\n",
      "TRAIN: [0 1] TEST: [2 3]\n",
      "TRAIN: [0 1 2 3] TEST: [4 5]\n",
      "TRAIN: [0 1 2 3 4 5] TEST: [6 7]\n",
      "TRAIN: [0 1 2 3 4 5 6 7] TEST: [8 9]\n",
      "TRAIN: [0 1 2 3 4 5 6 7 8 9] TEST: [10 11]\n"
     ]
    }
   ],
   "source": [
    "X = np.array([[1, 2], [3, 4], [1, 2], [3, 4], [1, 2], [3, 4]])\n",
    "y = np.array([1, 2, 3, 4, 5, 6])\n",
    "\n",
    "tscv = TimeSeriesSplit()\n",
    "print(tscv)\n",
    "\n",
    "for train_index, test_index in tscv.split(X):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    \n",
    "# Fix test_size to 2 with 12 samples\n",
    "X = np.random.randn(12, 2)\n",
    "y = np.random.randint(0, 2, 12)\n",
    "\n",
    "tscv = TimeSeriesSplit()\n",
    "print(tscv)\n",
    "\n",
    "for train_index, test_index in tscv.split(X):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97dcc683",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
